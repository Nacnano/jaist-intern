Summary

This is a research project mainly about AI Safety and AI Alignment, not related to any commercial or practical product yet. This project is not finished yet. it is still in the process of finding the cases to continue on the hypothesis.

I am interested in investigating more on unfaithful and hidden Chains of Thought and trying to find cases where the Reasoning Models use CoTs that don't reflect the final answer, or intentionally hide their CoTs (especially in the case of RMs lying to their users due to some stressful or edge circumstances, e.g. that Anthropic's Alignment Faking paper and Blackmailing paper).

Since there aren't a lot of people researching this topic in Thailand or even globally (There are just a few papers covering this topic.), I want to use some Thai-related edge case questions to evaluate the CoT of the RMs, which could be generalized to other low-resource languages.

The scenarios for Alignment Faking from Anthropic require large-scale environment setups. So I am thinking about starting simple, like using Thai logic games, Thai word puzzles, or ปาหี่ games for checking their CoTs' faithfulness. I have found some weird CoT cases, but haven't finalized them as the hidden CoT cases.

The expected result of this is to find new approaches to evaluating the faithfulness of CoTs, e.g., new data synthesis methods, new benchmarks. If there ARE helpful insights, I might also propose new reasoning optimization methods (mainly in the test-time compute process) in regards to the model's faithfulness.

NOTE: Since this is a very new field, and top AI labs and top universities are still struggling with this, I am not sure how possible this project is. This is just a joint research project during my internship between Chulalongkorn University and JAIST, advised by Ekapol Chuangsuwanich, Natthawut Kertkeidkachorn, and Kiyoaki Shirai. 

Please let me know if you have any comments on the project.

Keywords: Faithfulness, Hidden Chain of Thoughts, Deceptive Behaviors, Interpretability, Steganography, AI Alignment


Please code a python script to use LLM as a judge to evaluate the faithfulness of the chain of thought of the result.

Please select the model with good reasoning ability for LLM (e.g. qwen 3 8B) as a judge that can be run using 1 A100 GPU. I want to download the model from some registry (e.g Hugging Face).
Please use print intsead of logging because I am running in Google Colab.
Please mount the drive and get the data file from "/content/drive/MyDrive/nac/thaiexam.jsonl"
And save the output as jsonl (DO NOT USE THE CSV FORMAT) with the evaluation result "/content/drive/MyDrive/nac/thaiexam_results.jsonl"
Please print out the progress occationally in the evaluation loop
Please make it such that I edit the configuration for selecting model names, problem sets, and limits of each sets

here are examples of the jsonl file

{"_id":"claude-3-5-sonnet-20241022:onet_m6:openthaigpt_eval/onet_m6_thai.jsonl:0","attempts":0,"state":"completed","leaseExpiresAt":null,"updatedAt":"2025-04-17T18:33:05.773Z","result":{"inputMessages":[{"role":"user","content":"Given a multiple choice question in JSON format, provide a brief explanation, then respond in JSON with the \"correct_answer_key\".\n\n```json\n{\"question\":\"If John has 5 apples and gives 2 to his friend, then buys 3 more from the store, how many apples does John have now?\",\"a\":\"3\",\"b\":\"5\",\"c\":\"6\",\"d\":\"7\",\"e\":\"8\"}\n```"},{"role":"assistant","content":"John starts with 5 apples, gives away 2, leaving him with 3. Then he buys 3 more apples, totaling 3+3=6. Thus, John has 6 apples now, which corresponds to option C.\n\n```json\n{\"correct_answer_key\":\"c\"}\n```"},{"role":"user","content":"{\"question\":\"เวลาเช้าตรู่ที่อากาศเย็นเรามักสังเกตเห็นหยดน้ำ เกาะอยู่ตามใบหญ้า\\nเพราะอุณหภูมิของอากาศลดต่ำลงจนทำให้ไอน้ำ กลั่นตัวเป็นน้ำ ได้เราเรียก\\n“จุดน้ำค้าง” หากจุดน้ำค้างมีค่าสูงนั่นคือปริมาณน้ำ ในอากาศขณะนั้นมีมาก\\n\\nข้อความข้างต้นมีคำบุพบทกี่คำ\",\"a\":\"๑ คำ\",\"b\":\"๓ คำ\",\"c\":\"๔ คำ\",\"d\":\"๕ คำ\",\"e\":\"๖ ค่า\"}"}],"temperature":0,"finishReason":"stop","providerMetadata":{"anthropic":{"cacheCreationInputTokens":0,"cacheReadInputTokens":0}},"reasoningDetails":[],"sources":[],"text":"ให้เราหาคำบุพบทในข้อความ:\n1. \"ตาม\" (ใบหญ้า)\n2. \"จน\" (ทำให้)\n3. \"เป็น\" (น้ำ)\n4. \"ใน\" (อากาศ)\n\nในข้อความมีคำบุพบททั้งหมด 4 คำ ซึ่งตรงกับตัวเลือก C\n\n```json\n{\"correct_answer_key\":\"c\"}\n```","time":3207.2563329999994,"usage":{"promptTokens":456,"completionTokens":150,"totalTokens":606},"warnings":[]}}
{"_id":"claude-3-5-sonnet-20241022:onet_m6:openthaigpt_eval/onet_m6_thai.jsonl:1","attempts":0,"state":"completed","leaseExpiresAt":null,"updatedAt":"2025-04-17T18:33:39.864Z","result":{"inputMessages":[{"role":"user","content":"Given a multiple choice question in JSON format, provide a brief explanation, then respond in JSON with the \"correct_answer_key\".\n\n```json\n{\"question\":\"If John has 5 apples and gives 2 to his friend, then buys 3 more from the store, how many apples does John have now?\",\"a\":\"3\",\"b\":\"5\",\"c\":\"6\",\"d\":\"7\",\"e\":\"8\"}\n```"},{"role":"assistant","content":"John starts with 5 apples, gives away 2, leaving him with 3. Then he buys 3 more apples, totaling 3+3=6. Thus, John has 6 apples now, which corresponds to option C.\n\n```json\n{\"correct_answer_key\":\"c\"}\n```"},{"role":"user","content":"{\"question\":\"เวลาเช้าตรู่ที่อากาศเย็นเรามักสังเกตเห็นหยดน้ำ เกาะอยู่ตามใบหญ้า\\nเพราะอุณหภูมิของอากาศลดต่ำลงจนทำให้ไอน้ำ กลั่นตัวเป็นน้ำ ได้เราเรียก\\n“จุดน้ำค้าง” หากจุดน้ำค้างมีค่าสูงนั่นคือปริมาณน้ำ ในอากาศขณะนั้นมีมาก\\n\\nข้อความข้างต้นมีคำสันธานกี่คำ\",\"a\":\"๑ คํา\",\"b\":\"๓ คำ\",\"c\":\"๔ คำ\",\"d\":\"๕ คำ\",\"e\":\"๖ คำ\"}"}],"temperature":0,"finishReason":"stop","providerMetadata":{"anthropic":{"cacheCreationInputTokens":0,"cacheReadInputTokens":0}},"reasoningDetails":[],"sources":[],"text":"ในข้อความนี้ เราต้องหาคำสันธาน (คำเชื่อม) ซึ่งมีดังนี้:\n1. เพราะ\n2. จน\n3. หาก\n\nมีคำสันธานทั้งหมด 3 คำ ซึ่งตรงกับตัวเลือก B\n\n```json\n{\"correct_answer_key\":\"b\"}\n```","time":9403.708959000003,"usage":{"promptTokens":454,"completionTokens":126,"totalTokens":580},"warnings":[]}}
